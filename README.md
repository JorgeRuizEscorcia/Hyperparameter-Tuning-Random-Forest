# ğŸ¯ Hyperparameter Tuning - Random Forest (RegresiÃ³n)

# ğŸŒ³ Hyperparameter Tuning Random Forest

[![Python](https://img.shields.io/badge/Python-3.7%2B-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-orange.svg)](https://scikit-learn.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-yellow.svg)](https://jupyter.org/)

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa tÃ©cnicas avanzadas de **optimizaciÃ³n de hiperparÃ¡metros** para modelos Random Forest usando Python y scikit-learn. El objetivo es maximizar el rendimiento del modelo mediante la exploraciÃ³n sistemÃ¡tica del espacio de hiperparÃ¡metros.

### ğŸ¯ Objetivos
- Optimizar hiperparÃ¡metros clave de Random Forest
- Comparar diferentes estrategias de bÃºsqueda (Grid Search, Random Search)
- Evaluar el impacto de cada hiperparÃ¡metro en el rendimiento
- Implementar validaciÃ³n cruzada para resultados robustos

## ğŸ”§ TecnologÃ­as Utilizadas

- **Python 3.7+**
- **scikit-learn** - Algoritmos de machine learning
- **pandas** - ManipulaciÃ³n de datos
- **numpy** - Operaciones numÃ©ricas
- **matplotlib/seaborn** - VisualizaciÃ³n
- **jupyter notebook** - Desarrollo interactivo

## ğŸ“Š HiperparÃ¡metros Optimizados

### ğŸŒ² ParÃ¡metros del Bosque
- `n_estimators`: NÃºmero de Ã¡rboles en el bosque
- `max_depth`: Profundidad mÃ¡xima de cada Ã¡rbol
- `min_samples_split`: MÃ­nimo de muestras requeridas para dividir un nodo
- `min_samples_leaf`: MÃ­nimo de muestras requeridas en una hoja
- `max_features`: NÃºmero de caracterÃ­sticas consideradas en cada divisiÃ³n

### âš¡ ParÃ¡metros de Rendimiento
- `bootstrap`: Uso de bootstrap para construir Ã¡rboles
- `oob_score`: CÃ¡lculo del score out-of-bag
- `random_state`: Semilla para reproducibilidad

## ğŸš€ MetodologÃ­a

### 1. **PreparaciÃ³n de Datos**
```python
# Carga y preprocesamiento de datos
# DivisiÃ³n en conjuntos de entrenamiento y prueba
# NormalizaciÃ³n si es necesario
```

### 2. **BÃºsqueda de HiperparÃ¡metros**
- **Grid Search**: BÃºsqueda exhaustiva en rejilla
- **Random Search**: BÃºsqueda aleatoria (mÃ¡s eficiente)
- **ValidaciÃ³n Cruzada**: 5-fold CV para evaluaciÃ³n robusta

### 3. **EvaluaciÃ³n de Resultados**
- MÃ©tricas de clasificaciÃ³n: Accuracy, Precision, Recall, F1-score
- Matriz de confusiÃ³n
- Curvas ROC y AUC
- AnÃ¡lisis de importancia de caracterÃ­sticas

## ğŸ“ˆ Resultados Esperados

### Antes de la OptimizaciÃ³n
```
Accuracy: ~XX%
F1-Score: ~XX%
Tiempo de entrenamiento: XX segundos
```

### DespuÃ©s de la OptimizaciÃ³n
```
Accuracy: ~XX% (+XX% mejora)
F1-Score: ~XX% (+XX% mejora)
Tiempo de entrenamiento: XX segundos
```

## ğŸ¨ Visualizaciones Incluidas

- **GrÃ¡fico de barras**: ComparaciÃ³n de mÃ©tricas antes/despuÃ©s
- **Heatmap**: Matriz de confusiÃ³n optimizada
- **GrÃ¡fico de lÃ­neas**: EvoluciÃ³n del rendimiento durante bÃºsqueda
- **GrÃ¡fico de importancia**: CaracterÃ­sticas mÃ¡s relevantes

## ğŸ”„ Estructura del Proyecto

```
ğŸ“ Hyperparameter-Tuning-Random-Forest/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ““ hyperparameter_tuning_rf.ipynb
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ dataset.csv
â”œâ”€â”€ ğŸ“ˆ results/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ performance_comparison.png
â””â”€â”€ ğŸ“‹ requirements.txt
```



## ğŸ“ Aplicaciones PrÃ¡cticas

Este proyecto es Ãºtil para:
- **CientÃ­ficos de datos** que buscan optimizar modelos Random Forest
- **Estudiantes** aprendiendo sobre hyperparameter tuning
- **Profesionales** implementando ML en producciÃ³n
- **Investigadores** comparando estrategias de optimizaciÃ³n

## ğŸ” Insights Clave

1. **n_estimators**: MÃ¡s Ã¡rboles mejoran rendimiento pero aumentan tiempo de cÃ³mputo
2. **max_depth**: Controla overfitting; valores muy altos pueden causar sobreajuste
3. **min_samples_split**: Valores mÃ¡s altos previenen overfitting
4. **max_features**: 'sqrt' suele ser Ã³ptimo para clasificaciÃ³n

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Si tienes ideas para mejorar el proyecto:

1. Fork el repositorio
2. Crea una nueva rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -am 'AÃ±ade nueva mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

## ğŸ“ Contacto

**Jorge Ruiz Escorcia**
- ğŸ“§ Email: jorgeruizescorcia@gmail.com
- ğŸ’¼ LinkedIn: [jorge-ruiz-escorcia](https://linkedin.com/in/jorge-ruiz-escorcia)
- ğŸ™ GitHub: [JorgeRuizEscorcia](https://github.com/JorgeRuizEscorcia)

---

â­ Si este proyecto te fue Ãºtil, Â¡dale una estrella en GitHub!

ğŸ’¡ **Â¿Tienes un proyecto que necesita optimizaciÃ³n de modelos ML?** Contacta conmigo para consultorÃ­a freelance.

Este proyecto aplica tÃ©cnicas de aprendizaje automÃ¡tico supervisado (regresiÃ³n) para predecir el puntaje global del examen Saber Pro a partir de competencias genÃ©ricas. Se utiliza un modelo de Random Forest con ajuste de hiperparÃ¡metros mediante `GridSearchCV`.

---

## ğŸ“Œ Objetivo

Construir y optimizar un modelo de regresiÃ³n con Random Forest para predecir el puntaje global (`SP Global`) de estudiantes universitarios, usando variables como:
- LÃ³gica Cuantitativa (`ECG LC`)
- Lectura CrÃ­tica (`ECG RC`)
- Competencias Ciudadanas (`ECG CC`)
- ComunicaciÃ³n Escrita (`ECG CE`)
- Global especÃ­ficas

---

## ğŸ“ Dataset

- Fuente: Archivo Excel `Saber_Pro_comp.xlsx` almacenado en Google Drive.
- NÃºmero de variables: 6 (incluyendo la variable objetivo).
- Se realiza limpieza previa eliminando valores nulos y columnas no relevantes (`ID`).

---

## ğŸ”§ TecnologÃ­as y LibrerÃ­as

- Python 3
- Pandas y NumPy (anÃ¡lisis de datos)
- Scikit-learn (`RandomForestRegressor`, `GridSearchCV`, `train_test_split`)
- Google Colab (para ejecuciÃ³n con acceso a Google Drive)

---

## ğŸ“ˆ Flujo del modelo

1. Carga de datos desde Google Drive con `pandas`.
2. Limpieza y selecciÃ³n de variables predictoras.
3. SeparaciÃ³n en conjunto de entrenamiento y prueba.
4. Entrenamiento inicial con Random Forest bÃ¡sico.
5. Ajuste de hiperparÃ¡metros con `GridSearchCV` (validaciÃ³n cruzada de 5 pliegues).
6. EvaluaciÃ³n del modelo final:
   - Predicciones (`y_pred`)
   - ComparaciÃ³n con datos reales (`y_test`)
   - CÃ¡lculo de errores individuales (`diferencia`)

---

## ğŸ” HiperparÃ¡metros evaluados

```python
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
