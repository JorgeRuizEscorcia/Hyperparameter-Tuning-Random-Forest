# ğŸ¯ Hyperparameter Tuning - Random Forest (RegresiÃ³n)

# ğŸŒ³ Hyperparameter Tuning Random Forest

[![Python](https://img.shields.io/badge/Python-3.7%2B-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-orange.svg)](https://scikit-learn.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-yellow.svg)](https://jupyter.org/)

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa tÃ©cnicas avanzadas de **optimizaciÃ³n de hiperparÃ¡metros** para modelos Random Forest usando Python y scikit-learn. El objetivo es maximizar el rendimiento del modelo mediante la exploraciÃ³n sistemÃ¡tica del espacio de hiperparÃ¡metros.

### ğŸ¯ Objetivo
Construir y optimizar un modelo de regresiÃ³n con Random Forest para predecir el puntaje global (`SP Global`) de estudiantes universitarios, usando variables como:
- LÃ³gica Cuantitativa (`ECG LC`)
- Lectura CrÃ­tica (`ECG RC`)
- Competencias Ciudadanas (`ECG CC`)
- ComunicaciÃ³n Escrita (`ECG CE`)
- Global especÃ­ficas

Optimizar hiperparÃ¡metros clave de Random Forest
- Comparar diferentes estrategias de bÃºsqueda (Grid Search, Random Search)
- Evaluar el impacto de cada hiperparÃ¡metro en el rendimiento
- Implementar validaciÃ³n cruzada para resultados robustos

## ğŸ”§ TecnologÃ­as Utilizadas

- **Python 3.7+**
- **scikit-learn** - Algoritmos de machine learning
- **pandas** - ManipulaciÃ³n de datos
- **numpy** - Operaciones numÃ©ricas
- **matplotlib/seaborn** - VisualizaciÃ³n
- **jupyter notebook** - Desarrollo interactivo

## ğŸ“Š HiperparÃ¡metros Optimizados

### ğŸŒ² ParÃ¡metros del Bosque
- `n_estimators`: NÃºmero de Ã¡rboles en el bosque
- `max_depth`: Profundidad mÃ¡xima de cada Ã¡rbol
- `min_samples_split`: MÃ­nimo de muestras requeridas para dividir un nodo
- `min_samples_leaf`: MÃ­nimo de muestras requeridas en una hoja
- `max_features`: NÃºmero de caracterÃ­sticas consideradas en cada divisiÃ³n

### âš¡ ParÃ¡metros de Rendimiento
- `bootstrap`: Uso de bootstrap para construir Ã¡rboles
- `oob_score`: CÃ¡lculo del score out-of-bag
- `random_state`: Semilla para reproducibilidad

## ğŸš€ MetodologÃ­a

### 1. **PreparaciÃ³n de Datos**
```python
# Carga y preprocesamiento de datos
# DivisiÃ³n en conjuntos de entrenamiento y prueba
# NormalizaciÃ³n si es necesario
```

### 2. **BÃºsqueda de HiperparÃ¡metros**
- **Grid Search**: BÃºsqueda exhaustiva en rejilla
- **Random Search**: BÃºsqueda aleatoria (mÃ¡s eficiente)
- **ValidaciÃ³n Cruzada**: 5-fold CV para evaluaciÃ³n robusta

### 3. **EvaluaciÃ³n de Resultados**
- MÃ©tricas de clasificaciÃ³n: Accuracy, Precision, Recall, F1-score
- Matriz de confusiÃ³n
- Curvas ROC y AUC
- AnÃ¡lisis de importancia de caracterÃ­sticas

## ğŸ¨ Visualizaciones Incluidas

- **GrÃ¡fico de barras**: ComparaciÃ³n de mÃ©tricas antes/despuÃ©s
- **Heatmap**: Matriz de confusiÃ³n optimizada
- **GrÃ¡fico de lÃ­neas**: EvoluciÃ³n del rendimiento durante bÃºsqueda
- **GrÃ¡fico de importancia**: CaracterÃ­sticas mÃ¡s relevantes

## ğŸ”„ Estructura del Proyecto

```
ğŸ“ Hyperparameter-Tuning-Random-Forest/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ““ hyperparameter_tuning_rf.ipynb
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ dataset.csv
â”œâ”€â”€ ğŸ“ˆ results/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ performance_comparison.png
â””â”€â”€ ğŸ“‹ requirements.txt
```



## ğŸ“ Aplicaciones PrÃ¡cticas

Este proyecto es Ãºtil para:
- **CientÃ­ficos de datos** que buscan optimizar modelos Random Forest
- **Estudiantes** aprendiendo sobre hyperparameter tuning
- **Profesionales** implementando ML en producciÃ³n
- **Investigadores** comparando estrategias de optimizaciÃ³n

## ğŸ” Insights Clave

1. **n_estimators**: MÃ¡s Ã¡rboles mejoran rendimiento pero aumentan tiempo de cÃ³mputo
2. **max_depth**: Controla overfitting; valores muy altos pueden causar sobreajuste
3. **min_samples_split**: Valores mÃ¡s altos previenen overfitting
4. **max_features**: 'sqrt' suele ser Ã³ptimo para clasificaciÃ³n

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Si tienes ideas para mejorar el proyecto:

1. Fork el repositorio
2. Crea una nueva rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -am 'AÃ±ade nueva mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

## ğŸ“ Contacto

**Jorge Ruiz Escorcia**
- ğŸ“§ Email: jorgeruizescorcia@gmail.com
- ğŸ’¼ LinkedIn: [jorge-ruiz-escorcia](https://linkedin.com/in/jorge-ruiz-escorcia)
- ğŸ™ GitHub: [JorgeRuizEscorcia](https://github.com/JorgeRuizEscorcia)

---

â­ Si este proyecto te fue Ãºtil, Â¡dale una estrella en GitHub!

ğŸ’¡ **Â¿Tienes un proyecto que necesita optimizaciÃ³n de modelos ML?** Contacta conmigo para consultorÃ­a freelance.



